---
title: Scoping the Enterprise LLM Market
description: Naveen Rao has been building artificial intelligence technologies and companies for more than a decade. He founded Nervana Systems (acquired by Intel) and MosaicML (acquired by Databricks), and now serves as vice president of generative AI at Databricks. From chips to models, there are few people with a better pulse on how enterprises are using AI.In this inaugural episode of the AI + a16z podcast, Rao joins a16z partner Matt Bornstein and a16z enterprise editor Derrick Harris to discuss where we’re at in terms of large language model (LLM) adoption, as well as how LLMs will influence chip design and software refresh cycles. He also shares some of his personal story of watching AI technology — and awareness — grow from fringe movement to mainstream phenomenon.
---

# Scoping the Enterprise LLM Market
In the next 10 to 20 years, we will see the emergence of technologies capable of performing with agency, meaning these systems will be able to formulate hypotheses, create and execute actions, observe the outcomes, and refine their hypothesis generation processes. Although such technologies may need about 100 megawatts to operate—far more than the 20 watts our brains use—this signifies concrete progress. I am extremely excited and optimistic about these advancements. By the time I am 80, I believe we will have significantly impacted and transformed the world with these developments. I am Derek Harris, and you are listening to the A16Z AI podcast where we explore all aspects of artificial intelligence. Our team, along with leading founders, engineers, and researchers, discusses the latest advancements in the field. In our first interview-style episode, A16Z partner Matt Bornstein and I talk to Naveen Rao, the Vice President of Generative AI at Databricks. Naveen is a veteran in the AI sector, with a background in developing AI chips, initially at Qualcomm and then at other leading tech firms.

在接下来的10到20年中，我们将见证某些具有代理能力的技术的诞生。这些系统能够制定假设、创建并执行行动、观察结果，并更新其假设生成过程。尽管这样的技术可能需要约100兆瓦的能源——远超我们大脑的20瓦耗能——但这标志着实质性的进展。我对这些进步感到非常兴奋和乐观。当我80岁的时候，我相信我们将通过这些发展显著影响并转变世界。我是Derek Harris，您正在收听A16Z人工智能播客，在这里我们探索人工智能的所有方面。我们的团队，以及顶尖的创始人、工程师和研究人员，讨论该领域的最新进展。在我们的首个访谈风格的剧集中，A16Z合伙人Matt Bornstein和我与现任Databricks生成式AI副总裁Naveen Rao进行了对话。Naveen在AI领域是一个资深人士，有着在高通等领先科技公司开发AI芯片的经历。

Naveen Nelson founded AI startup Nirvana Systems in 2014, which was later acquired by Intel in 2016. After his tenure at Intel, Nelson founded Mosaic ML in 2021, shifting his focus to the software aspect, helping clients train their Machine Learning models and fine-tune Foundation models on an optimized technology stack. Databricks went on to acquire Mosaic in July 2023. Our discussion spans a wide range of topics in generative AI, with a particular emphasis on the development of the enterprise flair market. Nelson offers his insights into his preferences and experiences within the tech and business environments, noting that his involvement in technology follows him beyond the workplace. This episode was recorded shortly after the Nvidia GTC event, prompting us to initiate our conversation with Nvidia's ongoing leadership in managing AI workloads. Please remember that the information provided here is solely for informational purposes and should not be considered as legal, business, tax, or investment advice, nor should it be used to evaluate any investment or security, and is not aimed at any investors or potential investors in any A16Z fund.

纳文·尼尔森于2014年创立了人工智能初创公司Nirvana Systems，该公司随后在2016年被英特尔收购。在英特尔任职期间后，尼尔森于2021年创立了Mosaic ML，此时他将关注点转向了软件方面，帮助客户培训他们的机器学习模型，并在优化的技术栈上调优基础模型。Databricks在2023年7月收购了Mosaic。本次讨论涉及生成式AI的多个主题，尤其关注企业活力市场的形成。尼尔森分享了他对于偏好和在技术及商业环境中的经历的看法，指出他对技术的参与超出了工作场所。由于本集在Nvidia GTC事件之后录制，我们开始讨论了Nvidia在管理AI工作负载方面的持续领导地位。请注意，此处提供的内容仅供信息参考，不应被视为法律、商业、税务或投资建议，也不应用于评估任何投资或安全性，且不针对任何A16Z基金的投资者或潜在投资者。
Nvidia has excelled in identifying and capitalizing on various trends efficiently, including developments like low precision tensor cores among others. This proficiency has established them as a formidable competitor in the industry. Furthermore, the general discourse around the CUDA lock-in is no longer considered the primary reason for their dominance. Instead, Nvidia has set a gold standard that makes transitioning to other hardware platforms a risky endeavor. In our evaluations of new hardware, we primarily focus on achieving a more favorable Total Cost of Ownership (TCO), specifically assessing the effective floating-point operations per dollar. Despite the challenges posed by Nvidia's superior products, we can optimize usage substantially due to the mature software stack available, which remains a pivotal factor in their enduring market leadership. When considering alternative hardware platforms, I must carefully evaluate which details I am permitted to disclose.

Nvidia 在识别和利用各种趋势方面表现出色，包括低精度张量核心等发展，这种能力使它成为行业中的一个强大竞争者。此外，关于 “CUDA 锁定”的普遍讨论已不再被视为其主导地位的主要原因。相反，Nvidia 已设定了一个黄金标准，使得转移到其他硬件平台成为一种风险冒险。在评估新硬件时，我们主要关注实现更有利的总拥有成本 (TCO)，具体是评估每美元的有效浮点操作数。尽管 Nvidia 的优越产品带来了挑战，但由于现有的成熟软件栈，我们能够大幅优化使用，这是其市场领导地位持续存在的关键因素。在考虑替代硬件平台时，我必须仔细考虑哪些细节可以披露。
My brain immediately focuses on what is being developed by cloud platforms. Although there are some startups experimenting in this sector, my interest lies in what you are observing. We have engaged in discussions with all relevant parties; however, as of now, it is challenging to shift away from Nvidia. This is because, when attempting to develop models for a specific purpose, utilizing Nvidia represents the most direct route to achieving this goal. Introducing alternative options at this stage would only result in additional complications. Nevertheless, I anticipate that by the end of the year, the situation may evolve with new participants potentially facilitating the achievement of objectives with less difficulty. In our case, we are enhancing our software stack to simplify processes for our customers and to provide the best total cost of ownership through a familiar stack. Numerous developers are utilizing the Mosaics data brick stack. Indeed, by abstracting various hardware details, we aim to offer our customers greater flexibility in their choices.

我的注意力立即集中在云平台正在开发的内容上。虽然有些初创企业在这个领域进行实验，但我对你所关注的内容感到好奇。我们已与所有相关方进行了对话，然而到目前为止，从Nvidia转移仍然非常困难。这是因为，如果我们尝试为某些目的构建模型，使用Nvidia代表了达成目标的最直接路径。在现阶段引入其他选项只会带来更多的复杂性。不过，我预计到年底，情况可能会有所变化，可能会有新的参与者能够在减少困难的情况下实现目标。在我们的情况下，我们正在优化我们的软件堆栈，以简化客户的流程，并通过一个他们已经熟悉的堆栈提供最佳的总拥有成本。许多开发者正在使用Mosaics数据砖堆栈。实际上，通过抽象化各种硬件细节，我们的目标是为我们的客户提供更多的选择灵活性。
Language models, for quite some time, have predominantly been built around the transformer architecture. This trend appears to have facilitated an environment in which chip companies can design their products more narrowly, focused on a consistent range of workloads. There is a consensus that this is indeed the case. Reflecting on the past five to six years, there was a necessity to accommodate a diverse array of neural network families, including common nets, RNNs, LSTMs, among others. This diversity required that new hardware launching provide extensive support and optimization for various models, complicating their development. Currently, as mentioned before, the focus tends to be on either transformer models or diffusion models. Notably, diffusion models still represent significant workloads, emphasizing the ongoing importance of these particular models, which now involve a more specific set of computational primitives.

在过去相当长的一段时间内，语言模型主要是围绕变压器架构构建的。这一趋势似乎为芯片公司创造了一个环境，使其可以更狭窄地设计产品，专注于一致的工作负载范围。确实有一个共识认为这是事实。回顾过去五到六年，需要适应多种神经网络体系，包括通用网、RNN、LSTM等。这种多样性要求新硬件的推出提供广泛的支持和优化，使得它们的开发变得复杂。如前所述，当前的焦点往往是变压器模型或扩散模型。值得注意的是，扩散模型仍然代表着重要的工作量，强调这些特定模型的持续重要性，这些模型现在涉及更具体的计算原语。
Optimization of the current technology is possible, though its effectiveness remains questionable due to unresolved issues associated with transformers. The future developments in this field will likely stem from learnings acquired through transformers. Issues such as nations grounding persist and it's unclear whether they can be addressed within the existing transformer framework. Modifications will likely be necessary. Techniques like Rag, employed for augmenting generation by extending the context window to multiple documents through approximate search, illustrate a temporary solution. This approach, while currently adding value, is somewhat makeshift due to reliance on methods like approximate search and embedding models. There is a need to integrate such methods more fundamentally within the neural network paradigm to ensure a more authentic representation of truth.

目前技术的优化是可能的，尽管由于与变压器相关的未解决问题，其有效性仍有疑问。该领域的未来发展很可能基于通过变压器获得的学习。诸如国家基础这样的问题仍然存在，尚不清楚是否可以在现有变压器框架内解决这些问题。可能需要进行修改。采用Rag等技术通过近似搜索将上下文窗口扩展到多个文档以增强生成，这表明了一种临时解决方案。这种方法虽然目前增加了价值，但由于依赖近似搜索和嵌入模型等方法，这种方法在某种程度上是权宜之计。有必要将此类方法更根本地整合到神经网络范式中，以确保更真实地代表真理。
The adoption of the transformer as a standard paradigm in technology is beneficial for hardware vendors as it offers them the chance to enter and compete in the market. This year, we are likely to see increased competition which is advantageous for the industry. However, there is a tendency to overemphasize this architecture at present, which is common in technological developments. Adjustments to this paradigm might be necessary for future progress. Given your expertise in both hardware and software, could you explain the challenges of building custom chips to support various architectures like CNNs and others? Additionally, looking forward, how challenging will it be for the chip industry to adapt if we move away from Transformers? The essential principle in hardware development is constancy.

将变压器作为标准模式的采用对硬件供应商是有益的，因为它为他们提供了进入市场和竞争的机会。今年，我们可能会看到竞争的增加，这对行业是有利的。然而，目前有一种过分强调这种架构的倾向，这在技术发展中是常见的。未来可能需要对这一模式进行调整以便进步。鉴于您在硬件和软件方面的专业知识，您能否解释支持各种架构（如CNN等）的定制芯片构建面临的挑战？此外，展望未来，如果我们移除变压器，芯片行业适应的难度将有多大？硬件开发的基本原则是恒定不变。
Training the number of computational motifs, which means focusing on a set of operations that recur frequently, is essential. For instance, if matrix multiplication followed by a linear scaling term and a lookup table is a common sequence, it becomes possible to design hardware specifically optimized for this pattern. Thus, the process of crafting custom hardware revolves around identifying these dominant, recurring motifs and creating bespoke solutions for them. This approach, however, involves a trade-off with flexibility. CPUs, which were the primary technology model for an extended period, prioritize the sequential execution of instructions, a feature critical for applications such as Microsoft Word. Recently, the emphasis has shifted towards data parallelism, requiring a balance between maintaining sufficient flexibility for advancing algorithms like the Transformer and achieving efficient performance on certain basic operations. This balance is crucial in modern computing.

将计算模式的总数进行训练，意味着专注于反复出现的一组操作，这是至关重要的。例如，如果矩阵乘法后接一个线性缩放项和一个查找表是一种常见的序列，则可能设计出专门针对此模式优化的硬件。因此，定制硬件的设计过程围绕着识别这些主导且重复出现的模式，并为其创建专门的解决方案。然而，这种方法与灵活性之间存在权衡。在很长一段时间内，CPU作为主导技术模型，优先考虑指令的顺序执行，这对于诸如Microsoft Word之类的应用程序至关重要。最近，重点转向了数据并行性，这需要在保持足够的灵活性以支持像Transformer这样的先进算法和在某些基本操作上实现高效表现之间取得平衡。这种平衡在现代计算中至关重要。
When we began constructing software and hardware, such as in Nirvana, our focus was primarily on specific types of neural network architectures like multi-layer perceptrons and convolutional networks. However, developments like residual networks (ResNets), which are essentially convolutional networks but incorporate a distinct information flow, introduced certain challenges. These challenges led us to reconsider our approach to performing convolutions, exploring the possibility of executing them in the frequency domain rather than the time domain, which could alter the design patterns. Initially, GPU technology, which offered more flexibility, was advantageous. Yet, with the advent of more rigid, yet highly efficient architectures like transformers, we have the opportunity to develop systems that are somewhat less flexible but offer enhanced performance. Imagine pushing this to the ultimate limit where a fully trained neural network model, such as a popular one off the shelf, is directly integrated into silicon. This integration would allow for remarkable optimizations, where inefficiencies like zeros could be virtually eliminated without requiring a physical gate.

当我们开始在Nirvana等地构建软件和硬件时，我们主要关注特定类型的神经网络架构，如多层感知器和卷积网络。然而，像残差网络（ResNets）这样的发展，本质上是卷积网络，但采用了不同的信息流动方式，引入了一些挑战。这些挑战促使我们重新考虑执行卷积的方法，探索在频域而非时域执行卷积的可能性，这可能改变设计模式。最初，更具灵活性的GPU技术具有优势。然而，随着像变压器这样更为严格但效率更高的架构的出现，我们有机会开发出柔性较低但性能更强的系统。想象一下将这一理念推至极限，将一个完全训练好的神经网络模型，如市面上某个受欢迎的模型，直接集成到硅片中。这种集成将允许进行显著的优化，其中像零这样的低效率元素几乎可以被消除，而不需要物理门控。

In the podcast, it was explained that when using a logic optimization tool for building hardware that involves matrix multiplications containing many zeros, many transistors can be discarded, resulting from zeros propagating throughout the system. If a single, inflexible neural network gets hardcoded into the system, substantial optimizations can be realized. However, the commercial viability of such a product rests on its market potential and whether it can justify the development costs. The pertinent question remains whether the current market, dominated by players who train large foundational models, and perhaps a few others, might be realistic prospects for investing in such specialized and inflexible hardware. There appears to be potential markets for both versatile and specialized chips.

播客中提到，当使用逻辑优化工具来构建包含许多零的矩阵乘法的硬件时，可以丢弃许多由于零的传播而多余的晶体管。如果系统中硬编码了一个固定不变的神经网络，可以实现显著的优化。然而，这种产品的商业可行性取决于其市场潜力以及是否能够证明开发成本是合理的。一个关键问题是，当前由训练大型基础模型的主要玩家和可能的几个其他玩家构成的市场，是否是有现实可能投资于这种专用且不灵活的硬件的真实前景。对于功能全面和专用芯片来说，市场潜力似乎都存在。
Training models and constructing specialized models for various domains are currently essential, and there are numerous reasons for this. In regulated industries, for example, there is a demand for control. Moreover, companies strive for differentiation by creating models tailored to their data and customers, thereby establishing a unique offering compared to their competitors. Concurrently, there are major use cases of dominant technologies, such as ChatGPT or GPT-4, which have significantly evolved over the last year. Although some may regard them as merely one-year-old models, they are, in fact, continuously updated. Therefore, even if it is deemed a one-year-old model, it can remain valuable. If, for instance, it can process a sufficient number of inferences, or if it can attract enough subscribers—say 100 million users paying 20 dollars a month—that revenue can begin to justify the expense of developing specialized hardware.

在不同领域下，培训模型和构建专门模型是必需的，并且有很多原因促成了这一需求。例如，在受监管的行业中，存在对控制的需求。此外，企业为了区分市场竞争，致力于创建适应其数据和客户需求的模型，从而与竞争对手区分开来。同时，某些主导技术例如ChatGPT或GPT-4在过去一年中有了显著的发展。尽管有些人可能会认为它们只是一年期模型，实际上它们在不断更新中。因此，即使它被认为是一年期模型，它仍然可以保持其价值。例如，如果它能够处理足够多的推理，或者如果它能吸引足够多的订阅者——假设1亿用户每月支付20美元——那么这样的收入就可以开始证明开发专门硬件的花费是合理的。
Building a chip with such complexity typically incurs an upfront cost of around 30 million dollars. However, the cost per chip for running each inference would be significantly reduced, making this investment worthwhile. In recent times, our perceptions of hardware have shifted. Hardware is no longer seen as a large, costly, and unchangeable component, especially in an era where companies raise billions for funding rounds. It is feasible to design a new chip every six months with a cost of 30 million dollars, which is relatively manageable. This change in perspective allows us to develop financial models that justify the cost of creating new chips for specific purposes, based on the expected lifespan of the model and its usage or revenue potential. This rapid transformation in hardware development is remarkable, considering that just a few years ago, only major corporations like Google engaged in such activities. Now, even relatively new companies are adopting this approach.

建造一颗这样复杂的芯片，起始成本通常是3000万美元。然而，每颗芯片运行每次推理的成本将大大减少，这种投资是值得的。近年来，我们对硬件的看法发生了变化。硬件不再被视为一个庞大、昂贵且不可改变的部分，特别是在公司能筹集到数十亿资金的时代。每六个月设计一颗新芯片，成本为3000万美元，这在管理上是可行的。这种观点的转变使我们能够开发出财务模型，以此来证明为特定目的创建新芯片的成本是合理的，基于模型预期的寿命以及其使用或产生的收益潜力。硬件发展的迅速变革令人注目，考虑到就在几年前，只有像谷歌这样的大公司才进行此类活动。现在，即便是成立不久的公司也在采用这种方法。
I would like to transition from discussing emotional aspects to more technical aspects of software because it seems your preference lies with custom training models. However, I'm interested in understanding the trade-offs between different approaches. What would be the appropriate use case for each method? There is no single answer to this question. Our goal is to support our customers according to their needs and values. Currently, our primary business involves custom training. We expect that once these models are operational, the inference side will expand significantly. In a balanced state, I view it as a combination of fine-tuning and pre-training, which I collectively refer to as training. Meanwhile, inference only comes into play during deployment. Financially, I anticipate an almost equal split between training and deployment costs once deployment commences.

我想从讨论软件的感性方面过渡到技术方面，因为似乎你更倾向于自定义训练模型。然而，我对不同方法之间的权衡感兴趣。每种方法的适用场景是什么？这个问题没有确切的答案。我们的目标是根据客户的需求和价值观来支持他们。目前，我们的主要业务是自定义训练。我们预计一旦这些模型投入使用，推理部分将大幅增长。在一个平衡状态下，我认为这是微调和预训练的结合，我统称为训练。与此同时，推理只在部署过程中才会出现。从财务角度来看，一旦开始部署，我预计训练和部署成本将几乎平分。
When you implement a system in production, you collect feedback and seek to improve it through additional training. These two processes are synergistic. This dynamic could change, but currently inference alone does not suffice, as some suggest. Models serve as snapshots in time and are not permanent. From my observations, the lifespan of a model is typically around six months, even for advanced models like GPT-4. After such a period, significant modifications are often necessary. The strategy involves deploying a model for approximately six months, during which insights from its performance are used to enhance it further, followed by a cycle of retraining and improvement. These activities continuously support and enhance each other.

当你将一个系统投入生产使用时，你会收集反馈并通过额外的培训来寻求改进。这两个过程是相辅相成的。当前情况可能会变，但仅凭推断并不充分，尽管有人这么认为。模型作为时间的快照，它们不是永久的。根据我的观察，一个模型的寿命通常约为六个月，即便是像GPT-4这样的高级模型也是如此。在这样的周期之后，通常需要进行重大修改。这种策略涉及将模型部署大约六个月，期间使用其性能的洞察来进一步增强它，然后进行一轮培训和改进。这些活动不断相互支持和增强。
We don't really care; we will follow the trends, but so far, it seems that training and inference scale up simultaneously. There appears to be a shift in how applications are managed, with a typical lifespan of six months before a revision is required. This adjustment affects the operation of companies, offering a quicker turnaround for processes that are usually fundamental. Many firms may not be accustomed to this pace. In the semiconductor industry, for example, chips generally have a lifespan of about two years. After this period, a chip isn't necessarily obsolete, but it is considered old. Certain models, especially those that have passed compliance checks and other requirements, may remain in production much longer. For instance, chips used in automobiles are designed to last over ten years.

我们通常会随着趋势发展，但目前看来，训练和推理似乎是同时扩展的。这表明了应用程序管理方式的改变，通常应用程序的生命周期为六个月，之后需要进行更新。这种调整影响了公司的运营方式，为通常基础的流程提供了更快的周转时间，许多公司可能还不习惯这种速度。例如，在半导体行业中，芯片的一般寿命大约为两年。在此期间后，芯片并不一定过时，但已被视为陈旧。尤其是那些通过了合规性检查和其他要求的特定模型，可能会在生产中使用更长时间。例如，用于汽车的芯片设计寿命超过十年。
A car remains operational on the road for about 10 years, requiring numerous checks for its components, such as chips which have a long life span. In contrast, data centers operate at a quicker pace due to frequent upgrade cycles. Similarly, leading models that consistently receive feedback require more frequent updates. When I mention a six-month lifespan for a model, it doesn’t imply discarding it completely to build a new one from scratch. Rather, it means continuing to enhance the application's functionality based on the model's ongoing support. At Databricks, we have developed a system that allows for the collection of feedback from deployed models. This feedback is utilized to improve the models by creating supervised fine-tuning datasets, which are then used to fine-tune the model. Subsequently, an updated model is deployed. This forms a continuous development cycle.

在车辆行驶过程中，一辆车大约可以使用10年，这期间需要对其部件如芯片等进行大量检查，这些部件通常具有较长的使用寿命。与此相对的是，数据中心的运营节奏要快得多，因为它们经常进行升级换代。同样，那些经常接收反馈的前沿模型也需要更频繁地更新。我所说的模型有六个月的使用寿命，并不意味着要完全丢弃它并从头开始构建一个全新的模型。相反，这意味着要继续改进应用程序的功能，通过模型提供持续的支持。在Databricks，我们开发了一个系统，可以从部署中的模型收集反馈。利用这些反馈，通过创建监督式微调数据集来改进模型，然后使用这些数据集来微调模型。接下来，部署更新后的模型。这形成了一个持续的开发周期。
We frequently observe in the software industry that modifications are not necessarily due to a complete overhaul of the application's architecture but rather a result of continuous development. This includes receiving feedback, addressing bug reports, and resolving performance issues, which are then incorporated into the system, continuously refined, and subsequently deployed as updates. In a similar manner, I anticipate that data centers working with models will regularly update and version their systems as they transition to new iterations. The question then arises about the differences in implementing these practices within major tech companies like Google or OpenAI, compared to standard enterprises. It appears that there's a shift happening this year, suggesting that large language models (LLMs) are becoming accessible not just to experts but to a broader audience within various enterprises. This represents a significant change from past perceptions that these technologies were exclusive to specialists. This adaptation and democratization of advanced technologies were key components of our efforts at Mosaic.

我们在软件行业时常可以看到，改变并非总是因为整个应用程序的架构需要重建，而是因为持续的开发。这包括接收反馈、处理错误报告、解决性能问题，然后将这些反馈纳入系统，持续完善，并随后部署更新。类似地，我预见到在使用模型的数据中心，常常会更新和迭代他们的系统。那么，在像Google或OpenAI这样的大型技术公司内部实施这些做法与在标准企业内部实施有何不同呢？看来今年有一个转变，即大型语言模型（LLM）不再仅限于专家，而是在各种企业中变得更加普及。这从过去的看法转变而来，过去认为这些技术仅限于专家。这种先进技术的适应和普及是我们在Mosaic所做工作的重要部分。
Databricks has enabled anyone to access advanced computing capabilities. A notable example involves two skilled individuals who utilized Databricks' distributed integrated development environment to create a state-of-the-art coding model. This achievement, which previously could not have been accomplished within Google five or six years ago, highlights how smaller teams can now perform tasks that once required extensive resources. Companies such as Google and OpenAI had to assemble large teams to build and maintain their infrastructure, addressing any failures along the way. Databricks has simplified this process by developing tools that facilitate the management of infrastructure. Currently, many enterprises are leveraging these tools to train models efficiently, with over 100,000 models already trained. This development is significant, not merely emerging; it is already being utilized by companies to build their own models at a manageable cost.

Databricks 使得任何人都能够使用先进的计算功能。一个著名的例子是，两位熟练的开发者利用 Databricks 的分布式集成开发环境，创建了一个最先进的编码模型。这一成就在五六年前的 Google 内无法实现，突显了现在较小的团队如何能够完成过去需要大量资源的任务。像 Google 和 OpenAI 这样的公司以往需要组建大型团队来构建和维护其基础设施，并处理各种失败。Databricks 简化了这个过程，开发了一套工具来方便基础设施的管理。目前，许多企业正在利用这些工具高效地训练模型，已经训练了超过 100,000 个模型。这一发展非常重要，不仅仅是即将到来，它已经被公司用来以可管理的成本构建他们自己的模型。
It has become evident that achieving anything significantly meaningful for under a million dollars is quite challenging. This realization, combined with other factors, has underscored its importance. In terms of implementation, many enterprises are currently navigating this landscape. Typically, a considerable amount of responsibility lies under the Chief Information Officer (CIO). Often, it involves an IT department that manages infrastructure. However, there's usually a data scientist or a Machine Learning (ML) engineer in a particular line of business who handles data wrangling and utilizes various tools. This setup represents a shift from the traditional data platform arrangements, which were generally centralized under the CIO. Nowadays, we observe a slight deviation from this norm within organizations. It is common to find an ML team set up close to the core business operations where it is most relevant. These teams consist of competent individuals who need specific tools to develop and customize models according to their precise requirements. Additionally, there's a noticeable trend of graduates from prestigious universities like Stanford or Berkeley entering the field, equipped with the necessary skills to make significant contributions.

目前实现价值百万美元以下的有意义成果变得非常具有挑战性，这一认识和其他因素的结合，使其变得尤为重要。在实施方面，许多企业正在摸索这一新局面。通常，大量责任归属于首席信息官（CIO）。这通常涉及负责基础设施的IT部门。然而，通常会有一位在特定业务线的数据科学家或机器学习工程师负责数据整理和使用各种工具。这种安排与传统的数据平台安排形成了对比，后者通常是集中在CIO之下的。如今，在组织内部，我们观察到了从这一常规模式的轻微偏离。通常可以看到在与核心业务操作密切相关的地方设立机器学习团队。这些团队由需要特定工具来根据他们的确切需求开发和定制模型的能干人员组成。此外，我们还注意到，来自斯坦福、伯克利等名校的毕业生带着必要的技能加入这一领域，为行业做出了重要贡献。
Experts who are knowledgeable about natural language models and their optimization now understand the technical intricacies, at least conceptually. The expertise is now spreading across numerous enterprises, although it's unlikely to be concentrated in large teams. Instead, smaller teams, perhaps consisting of about five professionals, are becoming more prevalent. These teams require tools that simplify complex processes, and these are the customers we target. Could you explain how a smaller model might outperform GPT-4 currently? Although GPT-4 is trained on extensive data and possesses significant representational capabilities, most companies need it to function specifically within a particular domain, without the necessity for broader applications. This situation can be likened to the difference between a person who is moderately skilled in a wide range of tasks versus someone who excels exceptionally in a specific field.

目前了解自然语言模型及其优化技术的专家已经至少在概念上掌握了相关技术细节。这种专业知识正在逐渐传播到许多企业中，尽管不太可能在大团队中集中。相反，更常见的是由大约五名专业人员组成的小团队。这些团队需要简化复杂过程的工具，而这些正是我们的目标客户。您能解释一下为什么当前较小的模型有可能超越GPT-4吗？尽管GPT-4接受了大量数据的训练并具有显著的表现能力，但大多数公司需要它在特定领域内特定工作，而不需要更广泛的应用。这种情况可以类比于全能型与专精型人才之间的差异：前者在许多任务上表现一般，而后者在特定领域表现卓越。

The individual who excels in a specific field typically contributes more value to the world, since having numerous people each skilled in a particular area is beneficial. Consequently, a person who is a jack of all trades but a master of none tends to be less valuable. This principle is repeatedly observed across various domains. For instance, when you use domain-specific data, you can easily outperform GPT-4 with a smaller model trained specifically for that domain. This model isn't suited for general tasks. To clarify, if a model is exceptionally proficient at customer support for a bank, it will not perform well in discussing philosophy, solving mathematical equations, or handling SAT problems. It is designed solely for customer support, focusing on the bank's products, which is the priority for the business. Moreover, using such a highly trained large model for a specific use case constitutes complete and utter overkill.


擅长特定领域的个体通常能为世界带来更多价值，因为如果有许多人各自擅长一个领域，这将是有益的。相比之下，样样通、样样松的人往往价值较低。这一原则在不同领域中一再得到验证。例如，使用特定领域的数据，你可以轻松超越使用小型专用模型训练的GPT-4。该模型不适合于处理通用任务。明确来说，如果一个模型在银行客户支持方面表现出色，它在讨论哲学、解决数学问题或处理SAT问题方面的表现就不会很好。它仅设计用于客户支持，专注于银行产品，这是企业关心的重点。此外，为特定用例使用如此高度训练的大型模型完全是过度杀伤力。
Complete Streamlined Transcript:
The current trend is an increasing recognition that smaller, cost-efficient solutions can adequately address specific domain needs without requiring the extensive resources traditionally utilized. This realignment in strategy prompts a fundamental question: why opt for more expensive alternatives when more economically viable solutions exist? This perspective has gained traction, particularly with the assertion that smaller models, when properly trained or fine-tuned, can surpass capabilities of significantly larger models like GPT-4. However, concrete examples to support this claim seem scarce. A notable instance is Replete, an entity excelling in code completion through leveraging dataset derived from their own customer interactions. This isn't merely a function of a smaller targeted model but the integration of high-quality, domain-specific data—a resource that companies like OpenAI may not possess, as it falls outside their primary area of expertise.

意译结果:
当前趋势显示人们越来越认识到，小型且经济的解决方案能够在不需要使用传统所需的大量资源的情况下，充分满足特定领域的需求。这种策略上的重新定位引发了一个根本性的问题：当存在经济上更可行的选择时，为何还要选择成本更高的方案？这种观点尤其在以下声明中获得了广泛的支持：适当训练或调整的小型模型能够超越像GPT-4这样的大型模型。然而，支持这一断言的确切例子似乎并不多见。一个值得注意的例子是Replete公司，他们通过利用自己客户的互动数据，在代码完成方面取得了卓越的成就。这不仅仅是因为采用了针对性强的小型模型，还因为整合了高质量、特定领域的数据——这是像OpenAI这样的公司可能不具备的资源，因为这不是他们的主要专业领域。
They log all that data to train the model, resulting in a high-performing model. We also have an internal coding model at our enterprise company, which we use for a coding assistant. This model has outperformed GPT-4 significantly. It is important to note that we do not mandate the use of our models over GPT-4 within our company or among our enterprise clients. Both our internal teams and our clients have the freedom to choose whatever tools they deem best, including those from OpenAI. We use a variety of tools, and each team is encouraged to employ the most effective solution available. The preference for our models by some teams over others is a testament to their superior performance. Recently, we have started to demonstrate the capabilities of our own models, particularly in code generation and assistant tools, based on our understanding of the domain and the specific needs of our customers.

他们记录所有数据以训练模型，从而使模型性能显著提高。我们公司内部也有一个编程模型，用于编码助手，该模型的性能已大大超过了GPT-4。值得一提的是，我们公司以及我们的企业客户，都没有强制使用我们的模型而非GPT-4。无论是我们的内部团队还是客户，都可以自由选择他们认为最好的工具，包括来自OpenAI的工具。我们使用各种工具，并鼓励每个团队使用可用的最有效解决方案。一些团队选择我们的模型而非其他模型，证明了我们模型的优越性能。最近，我们开始使用我们自己的模型做演示，特别是在代码生成和助手工具方面，基于我们对该领域的理解以及对客户特定需求的了解。
We have datasets that characterize it. Now, we can proceed to refine the model significantly. A major trend observed at Andreessen Horowitz is the shift from supervised learning to unsupervised learning. Over the past eight years, our investments in AI companies have grown extensively, though it has spanned even longer than that. Reflecting on the era of supervised learning, a significant challenge was convincing customers. Large companies were required to assemble teams of 20, 50, or even 100 machine learning experts or engineers, gather vast amounts of data, label it, and then run it through a customized training process to determine the appropriate model architecture. This approach was complex, costly, and difficult to execute correctly. However, in the current era of unsupervised learning with large pre-trained models, these extensive preparations are no longer necessary. Nowadays, individuals can simply utilize an existing model from the shelf and create impressive demonstrations with relative ease.

我们拥有能够描述该模型的数据集。现在，我们可以对模型进行进一步的完善。在Andreessen Horowitz，我们观察到的一个重大趋势是从监督学习向非监督学习的转变。在过去的八年中，我们对AI公司的投资显著增加，实际上这一投资时间甚至更长。回顾监督学习时代，我们面临的一个主要挑战是说服客户。大公司需要组建由20、50甚至100名机器学习专家或工程师组成的团队，收集大量数据，对其进行标记，然后通过定制的训练流程来确定合适的模型架构。这种方法复杂、成本高昂且难以正确执行。然而，在当前的非监督学习时代，随着大型预训练模型的应用，这些繁琐的准备工作已不再必要。现在，人们可以简单地使用现成的模型，轻松创建令人印象深刻的演示。
You're presenting a compelling argument that fine-tuning one's model or even developing a new model from scratch can yield better results. It seems humorous to me, as it almost suggests a shift back towards supervised learning to some extent. Thus, the query arises: Have pre-trained models only surpassed the threshold and convinced people of their significance? Perhaps now a form of supervised learning or targeted training using proprietary data is the authentic solution. It appears the market merely required a push in this direction. Or could there be another factor at play here? Possibly, a balanced compromise has been established. However, I must slightly correct your terminology. This is not unsupervised learning; it is self-supervised and is intensively trained. The training's supervisory element arises from the natural sequence of words. Once you implement auto regression, labeling becomes unnecessary because the data inherently contains the labels, which is quite fascinating.

你提出了一个引人入胜的观点，认为微调自己的模型或者从头开始训练新模型可以取得更好的成效。这在我看来颇具讽刺意味，因为这似乎暗示着我们正在某种程度上回归到监督学习。因此，问题出现了：是不是预训练模型只是突破了常规，让人们认识到了它们的重要性？或许现在某种形式的监督学习或者针对特定数据的直接训练才是真正的答案。看起来市场只是需要一个推动力而已。还是说这里还有其他因素在起作用？可能我们找到了一个合适的折中方案。然而，我需要稍微纠正一下你的术语。这不是无监督学习；它是自监督学习，并且训练得很彻底。训练中的监督元素来源于词的内在顺序。一旦采用自回归，就不需要标记了，因为数据本身就内含标签，这非常巧妙。

To clarify what you are suggesting, when we train models using long sequences of text, the supervision, or labeling, is embedded because these texts were originally crafted by humans, which inherently structures them. This sequence of words is, therefore, intrinsically supervised, correct? Exactly. The intrinsic ordering of the words carries meaning, and understanding this meaning and its derivation is something that these models are capable of achieving, which is pretty remarkable. However, the point you are making extends beyond simple intermediary discussions. It appears that even though every one of these models is initially trained with supervised learning, supervised fine-tuning is essential. Without it, merely pre-training a model and deploying it could lead to immediate and unpredictable outcomes. This reflects some of the early challenges faced in AI development, such as the incident with Microsoft's Tay.

为了阐述你的想法，当我们使用长文本序列训练模型时，监督或标记已经因为这些文本最初是由人类编写的而内嵌其中，这为文本序列自然地加入了结构。因此，这些词语的序列本质上已具备监督。确实，词语的内在顺序带有意义，理解这种意义及其来源是这些模型能够实现的，这是相当了不起的。然而，你所表达的观点超出了普通的中间论点。从现在的情况看，尽管这些模型最初是通过监督学习进行训练的，监督式的微调是必不可少的。如果没有进行微调，仅仅预训练一个模型并投入使用可能会立即导致不可预测的后果。这反映了人工智能初期一些挑战，比如微软的Tay事件。
Starting with rough, almost uncontrolled models like Galactica during training phases with minimal fine-tuning resulted in erratic behaviors, making such strategies untenable for practical applications. Every model, at some point, undergoes a phase termed pre-training, where it assimilates the basic structure of language. Subsequently, specific patterns related to input-output configurations based on the training criteria are established. Questions like how to format a specific query or identifying inherently detrimental actions to avoid are examples where supervisory control intervenes. Though not as expansive as pre-training data sets, these supervised data sets have grown significantly in size and importance, making the crafting of a truly effective model hinge more on the quality of the supervised training. Recently, significant advancements have been made by integrating autoregressive, self-supervised training with multiple supervision strategies. Even with as few as 100 examples, if the training and loss formulation are executed correctly, profound results can be achieved.

起初采用像Galactica这样的模型进行培训时几乎没有进行细致调整，这导致模型行为出现异常，实际应用中难以采用这种策略。每个模型都会经历一个被称为预训练的阶段，在这一阶段，模型会吸收语言的基本结构。随后通过训练设定，建立起具体的输入输出模式。例如确定某个问题的格式处理方式或识别应避免的固有错误，这些都是监督控制介入的例子。尽管监督数据集的规模没有预训练数据集大，但这些数据集的大小和重要性已显著增加，一个模型的成功更多地依赖于优质的监督训练。最近，通过将自回归自我监督训练与多种监督策略结合，取得了重要进展。即便只有100个例子，如果训练和损失构建得当，也可以获得深远的效果。
The paradigm shift in my mind concerns the behavior modifications of the model based on self-supervised learning. Initially, in a purely supervised learning setting, one needed to create a high-quality dataset that was completely supervised. This process was not only difficult but also costly, and it involved a significant amount of machine learning engineering. As a result, it didn't gain as much traction due to its complexity. However, the current approach allows for a gradual improvement in performance. With a base model that adequately understands language and concepts, it becomes possible to incrementally integrate known information. The more information one has, the more one can enhance the model. Even with limited information, it's still feasible to achieve something useful. This model can then be deployed in controlled environments to gather feedback and facilitate further improvements. This new paradigm is revolutionary and is likely being considered for new projects by technology leaders across global enterprises.

该思维的转变涉及到模型在自我监督学习基础上的行为改变。在纯粹监督学习的环境中，人们需要创建一个完全受监督的高质量数据集。这个过程不仅困难而且成本高昂，并涉及大量的机器学习工程。因此，由于其复杂性，它并未广泛推广。然而，当前的方法允许性能逐渐改善。有了一个基础模型，能够充分理解语言和概念，就可以逐步融入已知信息。拥有的信息越多，就能越多地增强模型。即使信息有限，也能达到有用的成果。然后可以在受控环境中部署这个模型，收集反馈，促进进一步的改进。这一新范式具有革命性意义，目前全球各地的技术领导者可能都在考虑启动此类项目。
This is a critical technological shift, likely the most significant we've seen in the past two decades or more. One might wonder how to recognize if they are truly in a position to benefit from this technology unless they consult experts or engage with companies like Databricks to evaluate their existing problems, datasets, and suitability for this technology. The question of having the right dataset is crucial, yet it's reassuring to know that most companies already possess datasets that are either immediately usable or can be easily adjusted. For instance, companies with call center operations have access to transcripts that are perfect candidates for this kind of application. What you need are examples that demonstrate the desired behavior. The beauty of the pretraining combined with supervised fine-tuning and instructional fine-tuning approaches is that it allows one to start with a few examples, prove their value, and then incrementally scale the application.

这是一个关键的技术变革，可能是我们在过去二十年甚至更长时间里见证的最重要的变化。人们可能会想，除非咨询专家或与诸如Databricks之类的公司合作评估现有问题、数据集和适用性，否则如何确认自己真正能从这项技术中受益呢？拥有正确数据集的问题至关重要，但令人安心的是，大多数公司已经拥有可以立即使用或容易调整的数据集。例如，拥有呼叫中心业务的公司会有转录文本，这些是此类应用的理想选择。所需要的是展示所期望行为的示例。预训练与监督式微调和指导式微调结合的方法之美在于，它允许从几个示例开始，证明它们的价值，然后逐步扩展应用。
Most enterprises have a situation where, perhaps, a team member has successfully gathered a small, clean dataset from a recent customer experience initiative. However, alongside this, there exists a vast amount of older, disorganized data collected over the past two decades, scattered across various locations and of generally poor quality. With this one high-quality dataset at hand, companies are able to fine-tune their processes. This often serves as a motivation to revisit and systematically clean up the old data—akin to performing archaeological digs on data—thereby enabling the integration of this refined data to achieve even superior results. This emerging trend in data management can be likened to the adventurous efforts of Indiana Jones, where the discovery of one special artifact inspires a larger quest to uncover additional treasures and eventually, master the data universe.

多数企业中普遍存在的情况是：或许有某个团队成员成功地从最近的客户体验活动中收集了一小份干净且高质量的数据集。然而，与此同时，还存在着从过去二十年中收集的大量旧数据，这些数据分布在不同的地方，质量普遍较差且组织混乱。有了这份高质量的数据集之后，公司能够对其流程进行微调。这经常作为一个动机，激励公司重新审视并系统地清理旧数据，类似于对数据进行考古挖掘，从而使整合后的数据达到更优秀的成果。这种在数据管理中新兴的趋势可以比作是印第安纳·琼斯的冒险努力，其中一项特殊的发现激发了寻找更多宝藏的更大追求，最终掌握数据的宇宙。
Many digital-native businesses possess extensive data sets, which effectively encapsulate various aspects of their operations. These data sets include detailed information about buyer behavior and interactions, but historically, the know-how to utilize this data effectively has been lacking. The potential of AI to transform these data resources into valuable tools was envisioned over a decade ago, suggesting that one could derive actionable insights from these data pools. However, the realization of this potential has only recently become feasible. The challenge has been compounded by the fact that data has been accumulated over the past 20许多数字化初创企业拥有丰富的数据集，其中包含了企业运营的各个方面。这些数据集包括关于购买者行为和互动的详尽信息，但过去，并不清楚如何有效利用这些数据。十多年前，人们预见到人工智能（AI）能将这些数据资源转化为有价值的工具，能够从这些数据中提取可行的洞见。然而，这一能力直到最近才变得可行。这一挑战还因为数据长时间的累积而加剧，过去20年间数据以各种格式存储在不同的设备和位置，甚至可能有重要数据集被存储在某处的磁带驱动器中。现在，数据工程师可能需要从一堆尘封的资料中寻找信息，而这些企业的数据可能突然间变得难以处理。这种情况现在确实正在发生，因为人们意识到可以真正地利用这些数据来做一些事情。
In discussing the development of unique applications, the speaker expresses the significance of possessing an aspect that distinguishes them from their competitors. They touch upon the process of building something useful, and the description of these tools not as deterministic, but rather probabilistic, indicating a type of uncertainty or variability in outcomes. This evolution in thought and application is particularly challenging in regulated industries where there is a preference for deterministic models. Generally, in such industries, inputs are well-understood and outputs can be predicted with high precision. However, generative applications defy this model by introducing elements that are less predictable and thus more complex to characterize.

在讨论开发独特应用程序的过程中，发言者强调拥有与竞争对手不同的特性的重要性。他们讨论了构建有用之物的过程，并将这些工具描述为非确定性的，而是具有概率性的，这表明结果存在一种不确定性或可变性。这种思维和应用的演变在受监管的行业中尤其具有挑战性，因为这些行业偏好于确定性模型。通常在这些行业中，输入是众所周知的，输出可以高精度预测。然而，生成性应用挑战了这种模型，引入了不太可预测的元素，因此更复杂。
It generates new content through innovative mashups, creating outcomes that can often be unpredictable. For companies, the optimal approach involves distinguishing beneficial outcomes from detrimental ones with respect to their operations. This differentiation is achieved by developing appropriate evaluation metrics. In academic and industrial sectors, numerous evaluation standards, like NML U and Hell swag, are utilized to compare the efficacy of different models in various tasks. However, when faced with issues unique to a specific domain, evaluating success becomes challenging due to the absence of standardized tests. In practice, businesses often rely on intuitive judgments about human performance, similar to assessing an employee's suitability for client interaction or media representation based solely on subjective assessment, without the existence of a definitive test to conclusively determine competency.

创造新内容通常通过独创性的混搭来实现，这导致结果往往不可预测。对于公司而言，优化策略包括区分对企业有益及有害的结果。这一区分是通过制定适当的评估标准来实现的。在学术和工业领域，常用众多评估标准（例如NML U 和 Hell swag）来比较不同模型在各种任务上的效能。然而，面对特定领域内的独有问题时，评估成功变得更加挑战性，因为缺乏标准化的测试方法。在实际操作中，企业经常依靠对人类表现的直觉判断，比如基于主观评估来判断员工是否适合与客户互动或面对媒体，而没有一个明确的考试来确凿地确定能力。

In regulated industries, the challenge currently lies in developing evaluation criteria that provide clear indicators for comparing the merits of different models within a specific domain. We are actively advising companies to establish these success criteria, document them, and subsequently, we assist in creating evaluations tailored to these criteria. Regarding customer service, it appears straightforward to achieve improvements since the initial quality is typically low, and any enhancement is noticeable. Nonetheless, I must mention an incident where a chatbot for an airline was manipulated to sell a ticket for merely one dollar. I recall a blog post where you discussed the idea of considering Ulster as some form of structured representation, akin to a relational database, which essentially encapsulates the company's DNA. This concept is intriguing and merits further elaboration.

在受监管的行业中，目前的挑战在于开发能够提供明确指示的评估标准，以便在特定领域内比较不同模型的优劣。我们正在积极指导公司建立这些成功标准，对其进行文档化，并随后帮助他们创建针对这些标准的评估。关于客户服务，由于起点通常较低，任何改进都容易被察觉，因此看似容易实现提升。然而，我必须提及一个事件，即一个航空公司的聊天机器人被操纵仅售出一美元的机票。我记得您之前有篇博客文章讨论了将Ulster视为某种结构化表现的想法，类似于关系数据库，它本质上封装了公司的DNA。这一概念颇具启发性，值得进一步阐述。
To your point, we are observing that training on decades worth of data allows one to establish a comprehensive knowledge base about how this business functions. We constantly strive to identify and use terms that resonate with people, aiding their understanding of innovative concepts. These new concepts possess unique capabilities and are distinct from traditional databases; they serve more as a metaphor. Unlike standard databases, these new models can not only store data and knowledge, but they also have the ability to perform reasoning over this data. This occurs during either the training or tuning phases. When new data is introduced, these models can begin to identify useful interpretations of that data, which are crucial for conducting reasoning. For example, if I were to start using specialized terminology from PubMed related to genetics, someone unfamiliar with genetics might quickly feel lost.

我们注意到，通过对数十年数据的训练，可以建立起关于这个行业运作方式的全面知识库。我们不断寻找能够引起人们共鸣的术语，帮助他们理解新概念。这些新概念具有独特的能力，与传统数据库有所不同；它们更像是一种比喻。这些新型模型不仅可以存储数据和知识，还能对这些数据进行推理处理。这一过程发生在训练或调优阶段。当引入新数据时，这些模型可以开始识别数据的有用解释，这对进行推理至关重要。例如，如果我开始使用PubMed中与遗传学相关的专业术语，不熟悉遗传学的人可能会很快感到迷茫。
After repeated exposure to specific terminology, comprehension starts to develop regarding the theoretical frameworks of genetics such as how genes function, the role of a stop codon, and what a promoter entails. The concepts become more understandable, and with this foundational knowledge, new information can be evaluated more effectively, recognizing aspects that are particularly intriguing based on this framework. This advanced custom reasoning plays an essential role in understanding. As the industry evolves, the term reasoning is now used more comfortably without causing confusion like it did previously. A few years ago, mentioning reasoning might have been met with uncertainty, but today, it is possible to define more clearly as it involves forming a specific conceptual framework around data. This sort of tailored reasoning occurs when you introduce bespoke data or adjust training models.


通过反复接触特定术语后，人们开始理解遗传学的理论框架，例如基因如何运作、终止密码子的功能以及启动子的含义。这些概念变得更易理解，有了这个基础知识，新信息能更有效地被评估，识别基于这一框架的特别有趣的方面。这种高级的定制推理在理解过程中扮演着重要角色。随着行业的发展，“推理”这一术语现在使用起来更加舒适，不再像之前那样造成混淆。几年前，提到“推理”可能会遇到不确定性，但今天，可以更清晰地定义，因为它涉及围绕数据形成特定的概念框架。当你引入定制数据或调整训练模型时，就发生了这种定制推理。
We are currently witnessing a transition from the traditional database metaphor to a new paradigm, characterized by the development of custom reasoning engines. This evolution reflects the ongoing phenomenon wherein businesses are able to manage custom data, represent it in meaningful ways, and leverage it effectively for their operational needs. For instance, these advancements enable businesses to perform more complex reasoning processes rather than merely handling data.

In the realm of data infrastructure, especially at the platform layer, there is typically a significant inertia; changes are slow and technologies like databases tend to remain in use for extended periods. However, foundational models in data infrastructure appear to be rapidly evolving. Unlike traditional databases that primarily process data, these models are capable of performing advanced reasoning tasks, which supports faster and more dynamic developments within companies. This raises a crucial question regarding how foundational models should be integrated and considered within the broader data infrastructure, given their rapid pace of development and enhanced capabilities.

我们目前正在从传统的数据库模式过渡到一个新的范式，这个新范式以自定义推理引擎的开发为特征。这种演变反映了一个持续的现象，即企业能够管理自定义数据，以有意义的方式表示它，并有效地利用它来满足其运营需求。例如，这些进展使企业能够执行更复杂的推理过程，而不仅仅是处理数据。

在数据基础设施领域，尤其是在平台层面，通常存在显著的惯性；变化缓慢，像数据库这样的技术往往会长期使用。然而，数据基础设施中的基础模型似乎正在快速发展。与主要处理数据的传统数据库不同，这些模型能够执行高级推理任务，支持公司内更快速和更动态的发展。这引发了一个关键问题，即应如何将基础模型整合并视为更广泛的数据基础设施的一部分，鉴于它们的快速发展步伐和增强的能力。
Certainly, I will transcribe the podcast dialogue to a form suitable for written language while maintaining the integrity and detail of the original conversation. Here is the result:

Currently, it seems we are not committing to a single foundational model for an extended period. This phenomenon is reminiscent of the early days of databases. I remember, probably around the time I was in middle school, when databases like Oracle were gaining prominence and many companies were emerging in the early 90s. At that time, companies were hesitant to commit to a single database for long, as new technologies were continually emerging that were faster and better, each with unique schemata tailored to specific data. A large language model can be likened to a flexible schema that adapts based on the data it processes. Previously, we aimed to design schemata that were intrinsically superior for certain applications, like those supporting real-time operations but optimized for better recall.

目前，我们似乎不打算长期坚持单一的基础模型。这与早期的数据库发展情况有些相似。我记得大概在我上中学的时候，Oracle 等数据库开始变得重要，而且许多公司在 90 年代初期开始崛起。在那个时候，由于不断有更快更好的新技术涌现，公司们通常不会长时间地承诺使用单一的数据库，每种新技术都有其独特的数据模式。大型语言模型可以被看作是一种灵活的数据模式，它根据处理的数据自适应地形成模式。而在以前，我们则致力于设计对特定应用更有内在优势的数据模式，比如那些支持实时操作但在数据回调方面有更好表现的模式。

The discussion was centered on how in the past companies might opt for faster databases that could handle very large numbers of keys, which presented certain trade-offs. It was observed even then that companies would likely not commit to a single database for prolonged periods. However, current patterns have become very established, allowing companies to commit to a database for an extensive duration due to its maturity and reliability. This database commitment serves as the fundamental base of a business nowadays. Although foundation models have not yet reached this level of dependability, this shift is driving the increase in domain and customer specificity in technology applications. Once a model is developed that thoroughly understands a specific domain, the vision is for such a model to become more agentic and autonomously manage vast amounts of data continuously. This could allow it to discover significant insights autonomously, such as potential cost reductions in a supply chain.


本次讨论主要关于过去公司在选择数据库时，可能会倾向于选择处理速度快且能管理大量密钥的数据库，这种选择涉及到一定的权衡。即便在过去，公司也不太可能长期只依赖单一数据库。如今，这种模式已变得非常固定，公司能够因数据库的成熟和可靠性而长期依赖它，这已成为公司业务的根基。虽然基础模型尚未达到这种可靠程度，但这种转变正在推动技术应用领域逐渐增加域和客户的特异性。一旦开发出真正理解特定领域的模型，该模型被设想为将变得更加有主动性，并能持续自动管理大量数据。这使其有可能自主地发现重要洞察，例如可能在供应链上降低成本的方式。
We have not yet reached the point where we possess a system capable of deeply understanding my business and providing customized reasoning along with novel insights that I can consistently trust. However, once we achieve this, it will mark the advent of a stable, mature paradigm that outlives the typical six-month lifecycle. Naveen, you have extensive experience in this field, having observed it from various perspectives, and I have always regarded you as an especially thoughtful individual. Thank you. Could you share your experiences on a personal level? For instance, you founded a highly successful company that was later acquired by a major corporation. After retaining your position there for some time, you left to establish another startup. Many of us in the AI community have been anticipating the day when AI would fully function as expected, a sentiment I personally resonate with. Moreover, a significant number of newcomers are experimenting with AI or learning about it for the first time.

我们尚未到达拥有能够深入理解我的业务并提供定制化推理以及我能持续信赖的新奇见解的系统的阶段。然而，一旦我们实现这一点，将会迎来一个比典型的六个月生命周期更长久的稳定、成熟的范式。Naveen，你在这个领域有着丰富的经验，从多个角度观察它，我始终认为你是一个特别有思考深度的人。谢谢你。你能从个人层面分享一下你的经历吗？例如，你创立了一个非常成功的公司，后来被一家大公司收购。在那里工作了一段时间后，你离开并又创立了另一家创业公司。我们许多人在AI界一直在等待AI真正起作用的那一天，我个人也有同样的感受。此外，还有许多新人第一次尝试使用AI或学习AI。
You mentioned how it saddens you that you're not currently in college, particularly because students are learning about convolution in AI. This makes me reflect on my personal journey through the field of artificial intelligence and what the current trends mean to me. My interest in this area has been deep-rooted, and over the years, my engagement has been both extensive and intensive. Initially, I spent ten years in the industry as a computer and software architect. Motivated by the intriguing question of whether we could imbue machines with intelligence in an economically viable way, I returned to academia to pursue a Ph.D. in neuroscience. The economic aspect is crucial because without viability, technologies do not gain traction, fail to spread, and ultimately do not transform our world. My passion lies in turning technologies into products, as this process underscores their value. When customers invest in a product, it signifies that they recognize its worth in solving relevant problems and substantially enhancing their business.

您提到现在不在大学学习让您感到遗憾，特别是因为学生们正在学习人工智能中的卷积技术。这让我思考了我的人工智能之旅以及当前趋势对我意味着什么。我对这个领域的兴趣根深蒂固，多年来，我的参与既广泛又深入。最初，我在行业中担任了十年的计算机和软件架构师。受到一个有趣的问题的驱动——我们能否以经济上可行的方式使机器具备智能——我返回学术界攻读神经科学博士学位。经济方面至关重要，因为没有可行性，技术无法获得推广，无法扩散，最终也无法改变我们的世界。我热衷于将技术转化为产品，因为这个过程凸显了它们的价值。当客户对一个产品进行投资时，这表明他们认识到其解决问题的价值，并且能够实质性地增强他们的业务。
When a consumer chooses to pay for a product, it signifies significant trust and value, which, once established consistently, demonstrates real value in the market. Indeed, the potential of AI to add considerable value has been a long-standing anticipation. We've harbored vast and imaginative concepts about building intelligent machines since the mid-2000s. Many of these ideas are resurfacing as technology progresses. Techniques like backpropagation, convolutional networks, and transformers, while sometimes seeming to reach only a local minimum, collectively push towards a more comprehensive understanding of potential intelligence. It is exhilarating to witness the concept of machine intelligence becoming mainstream. All discussions, even the less serious ones about scenarios such as robots overtaking the world, are intriguing to me because they reflect a broader engagement with the notion of advanced technology.

当消费者选择为产品付费时，这表明了显著的信任和价值，一旦这种信任和价值能够连续不断地建立，就展示了市场中的真实价值。确实，人们长期以来一直期待人工智能能够增加更大的价值。从2000年代中期开始，我们就怀有关于构建智能机器的广泛而富有想象的概念。许多这样的想法随着技术的进步重新浮出水面。像反向传播、卷积网络和变换器这样的技术，虽然有时似乎只到达了局部最小值，但它们共同推动了对潜在智能更全面的理解。见证机器智能概念成为主流是非常令人兴奋的。所有的讨论，即使是关于机器人统治世界这类不太严肃的话题，对我来说也是非常有趣的，因为它们反映了人们对先进技术概念的更广泛关注。
We have now integrated this part of the conversation into our normal social constructs; it's no longer considered an unusual or marginal topic. For many years, I was associated with these unconventional subjects, but they are now gaining significance and are expected to bring substantial value. As the acceptance of these ideas increases, we will see more investment, which will help address existing challenges and lead to innovative problem-solving approaches, thereby revolutionizing the existing paradigms. In the next 10 to 20 years, I anticipate the development of systems capable of autonomous agency. Such systems will be able to generate hypotheses, initiate and perform actions, observe the outcomes, refine their hypothesis formulation, and consistently apply this process in complex behavioral situations. This prospect is quite fascinating. Looking back, a decade ago, I was uncertain about our progress towards these goals, but now, it appears we have gathered enough fundamental components to make this feasible.

我们现在已将这部分对话融入我们常规的社会构建中；它不再被视为一个不寻常或边缘的话题。多年来，我一直与这些非传统的主题相关联，但它们现在正变得越来越重要，并有望带来重大价值。随着这些想法的接受度增加，我们将看到更多的投资，这将有助于解决现有的挑战，并引领创新的解决问题方式，从而彻底改变现有的范式。在未来10到20年，我预期将开发出能够自主行动的系统。这样的系统将能够生成假设、发起和执行行动、观察结果、完善其假设的制定，并在复杂的行为情境中一贯地应用这一过程。这一前景非常令人兴奋。回顾过去，十年前我对我们实现这些目标的进程感到不确定，但现在看来，我们已收集到足够的基本组件，使这成为可能。


We're contemplating whether it will take 100 megawatts of power. It's certainly not the mere 20 watts of energy that the human brain utilizes, but it represents significant progress. I am extremely enthusiastic and optimistic about the future. When I am 80 years old and reflecting on the past, I believe we will have made substantial advances and fundamentally changed the world. This is indeed very exciting. Although it is frustrating in the short term, and here 'short term' refers to a span of 10 years, it's important to appreciate that this isn't a minor undertaking; it's a century-long transition. I wonder, was it more enjoyable being considered part of the fringe group, vocally advocating for the significance of AI when no one believed in it, or is it more fulfilling now, being celebrated with billion-dollar successes, desired as a guest on numerous podcasts, and featuring across headlines in every newspaper? On a personal note, I must say, it has become easier to explain what I do.


我们在考虑是否需要100兆瓦的能量。这显然并不像人脑那样只需要20瓦的能量，但这代表了重大的进步。我对未来极其兴奋和乐观。当我80岁回顾过去时，我相信我们将会实现重大进步，并从根本上改变世界。这确实令人非常兴奋。尽管从短期来看这很令人沮丧，而这里的‘短期’指的是10年的时间，重要的是要认识到这不是一项小工程；这是一个世纪长的转变。我想知道，是作为被认为是边缘小众、大声疾呼AI重要性、在没有人相信的时候支持AI更有趣，还是现在作为亿万富翁、受邀参加无数播客节目并成为各大报纸头条的感觉更令人满足？从个人角度来说，我必须说，现在解释我所做的事情确实变得更容易了。

This made the aspect concerning my wife easier, I would say, though it was somewhat annoying since people just wanted to discuss that topic. Nowadays, everyone has their own favorite theories. They seem eager to discuss these theories and solicit my opinion on them. At times, I simply wish to change the subject. For instance, when I'm taking a day off, I want to talk about something different. However, overall, I am quite happy and excited about the current direction of the world. Being a sideshow is not as enjoyable, to be honest. When you are constantly labeled as a sideshow, it demands passion to continue. This passion can become a source of strength. Ultimately, the purpose of this passion and strength is to create something meaningful and enduring, something that truly impacts the course of human evolution.

这部分有关我的妻子的事情变得更容易一些，我想说，尽管这样也有些烦人，因为人们只是想谈论那个话题。现在，每个人都有自己喜爱的理论，他们似乎很渴望讨论这些理论并征求我的意见。有时，我真的希望能换个话题。比如，当我休假的时候，我就想谈谈别的事情。但总的来说，我对世界的发展方向感到非常高兴和兴奋。坦白说，被视作配角并不那么有趣。当你不断被标记为配角时，你需要激情才能继续前行。这种激情能够成为力量的来源。最终，拥有这种激情和力量的目的是为了创造一些有意义、持久的事物，一些真正能改变人类进化进程的事物。
That's what I'm here for. I am here to be a part of building the next set of technologies that truly enable humans to influence the world in greater and more profound ways. Amazing. Hopefully, you enjoyed listening to Convened as much as we enjoyed speaking with him. We have some more exciting new episodes to come, as well as more from the A16Z archive. So subscribe to the feed so you don't miss them. Thank you again for listening.

这就是我存在的意义。我参与构建下一代技术，使人类可以更深远和强大地影响世界。希望你们喜欢听Convened的分享，就像我们喜欢和他对话一样。接下来还有更多激动人心的新节目以及A16Z档案的内容。因此，请订阅我们的频道，确保不错过这些精彩内容。再次感谢你的聆听。
